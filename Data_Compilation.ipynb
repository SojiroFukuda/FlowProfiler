{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This jupyter notebook provides the guidance of data compilation procedures. See each .py file for the detailed algorithm.\n",
    "For users, two sets of flow profile data from our flume experiments conducted at Total Environment Simulator (TES), the Deep accompany this code.\n",
    "By running this jupyter notebook, you can reproduce the interpolated/extrapolated profiles we used in the analysis of our works.\n",
    "\n",
    "# Explanation of each folder and file #\n",
    "data/TC/meta/metadata.csv: A csv file where all the meta informatinon (Slope, channel width, etc.) of each experiments are kept.\n",
    "\n",
    "data/TC/Paper/: there are two folders inside where the flow profile data of each set of the experiment are kept.\n",
    "\n",
    "Export/: The output files will be seved in this folder.\n",
    "    Export/Profiles/: PDF figures of estimated interpolated/extrapolated flow profiles of each run.\n",
    "    Export/Parameter_txt/: Characteristic flow parameters calculated from the interpolated/extrapolated flow profile are saved as a .txt file.\n",
    "    Export/Profile_txt/: The coordinates (500 points each) of the interpolated/extrapolated profile are saved as a .txt file.\n",
    "    \n",
    "# Python codes\n",
    "database.py: folder paths and paper referecens are kept.\n",
    "\n",
    "flowprofiler.py: data handling for each run. Each step of interpolation/extrapolation are implemented in this file, which eventually combined and conducted in the main.py.\n",
    "\n",
    "main.py: data handling of each set of experiments.\n",
    "    > main.set_exp('Name of a set of experiment', 'meta data', 'path of the original data') \n",
    "    Conduct data compilation from the given name of the experiment, importing the meta data from a csv file and the original measurment data.\n",
    "\n",
    "figformat.py: for the aesthetics of figures. Set dimension, font, format of each figure.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Packages\n",
    "import database as db # database of ref, path, data, figure, flow parameter handling\n",
    "import main # script for data compilation\n",
    "import os # file management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data compilation of Turbidity Currents\n",
    "refs = db.get_PaperDict() # refs of each source\n",
    "exps = [] # list for the compiled sources\n",
    "for ref in refs:\n",
    "    exp = main.set_exp(ref,db.TC_info,db.TC_Paper_DIR + os.sep + ref + os.sep + db.Coord_dir) # data compilation\n",
    "    result = main.export_results(exp,db.EXPORT_DIR) # export data (profiles, depth-averaged params) into .txt and .csv files\n",
    "    exps.append(exp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw Profiles of Turbidity Currents\n",
    "for exp in exps:\n",
    "    main.draw_profile(exp,db.EXPORT_DIR) # draw interpolated and extrapolated flow profiles and save it to db.EXPORT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
